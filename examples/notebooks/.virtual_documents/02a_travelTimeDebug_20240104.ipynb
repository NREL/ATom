%load_ext autoreload
%autoreload 2

# hardware
import os
# analysis
import numpy as np
import xarray as xr
import pandas as pd
from scipy.integrate import simps
from scipy.interpolate import RegularGridInterpolator
# vis
import matplotlib.pyplot as plt
plt.style.use('seaborn-v0_8-deep')

# Acoustic tomography
import atom
# config stuff
from hydra import initialize, compose
from hydra.utils import instantiate


with initialize(version_base=None, config_path="../../conf/"):
    cfg = compose(config_name="configs",)





### Array data
atarray = instantiate(cfg.atarray)
atarray.setupPathIntegrals()

## Constants
constants = instantiate(cfg.constants)

# ModelGrid object
mg = atom.fluctuatingField.ModelGrid(
    nModelPointsX=51, 
    nModelPointsY=51, 
    modelLimsX=np.array([-50,50]), 
    modelLimsY=np.array([-50,50])
)
mg.buildModelGrid()



datapath = '/Users/nhamilt2/Documents/ATom/data/Data_collection_20190815/'
datafiles = [datapath+x for x in os.listdir(datapath)]
datafiles.sort()
timestamps = list(set([x.split('/')[-1].split('_')[0] for x in datafiles]))
timestamps.sort()


raw_ttlist = []
corrected_ttlist = []
aux = []
for timestamp in timestamps:
    ### Microphone data
    audiodata = instantiate(cfg.audiodata)
    mainDataPath = f"/Users/nhamilt2/Documents/ATom/data/Data_collection_20190815/{timestamp}_AcouTomMainData.txt"
    try:
        audiodata.loadData(mainDataPath)
    except:
        print(f'skipping {timestamp}')
        continue

        ### Auxiliary data
    auxdata = instantiate(cfg.auxdata)
    auxDataPath = f"/Users/nhamilt2/Documents/ATom/data/Data_collection_20190815/{timestamp}_AcouTomAuxData.txt"
    auxdata.loadData(auxDataPath)
    aux.append(auxdata.ds)
    
    ## TravelTimeExtractor
    ttextractor = atom.signalProc.TravelTimeExtractor(
        cfg.traveltimeextractor,
        atarray=atarray.ds,
        audiodata=audiodata.ds,
        auxdata=auxdata.ds,
        correctSignalDelayEstimate=False
    )
    ttextractor.extractTravelTimes()
    raw_ttlist.append(ttextractor.ds)
    
    ## TravelTimeExtractor
    ttextractor = atom.signalProc.TravelTimeExtractor(
        cfg.traveltimeextractor,
        atarray=atarray.ds,
        audiodata=audiodata.ds,
        auxdata=auxdata.ds,
        correctSignalDelayEstimate=True
    )
    ttextractor.extractTravelTimes()
    corrected_ttlist.append(ttextractor.ds)


# Auxiliary data
ads = xr.concat(aux, dim='new')
ads['uDir'] = np.arctan2(ads.v, ads.u)
ads = ads.assign_coords(time=pd.timedelta_range(start=0, periods=len(ads.time), freq='0.05S'))

# Raw (uncorrected) travel time data
rttds = xr.concat(raw_ttlist, dim='new')
rttds['time'] = rttds['frame']*0.5
rttds['time'].values = pd.timedelta_range(start=0, periods=len(rttds.frame), freq='0.5S')
rttds = rttds.swap_dims({'frame':'time'})

# Corrected travel time data
cttds = xr.concat(corrected_ttlist, dim='new')
cttds['time'] = cttds['frame']*0.5
cttds['time'].values = pd.timedelta_range(start=0, periods=len(cttds.frame), freq='0.5S')
cttds = cttds.swap_dims({'frame':'time'})


delta_theta = atarray.ds.pathOrientation - ads.uDir.resample(time='60S').mean()
theta_i = atarray.ds.pathOrientation
Li = atarray.ds.pathLength

# detected - expected signal arrival times
tt_err = ttds.timeDeltas 
tt_err_mean = tt_err.mean(dim='time')
# estimated
tt_est = ttds.expectedTravelTimes
# Measured
tt_meas = ttds.filteredMeasuredTravelTimes#(ttds.detectedSignalTimes.unstack() - audiodata.ds.speakerSignalEmissionTime).stack(pathID=['spk','mic']).dropna(dim='pathID', how='all')
# Fill NaN values with the mean along the 'x' dimension
tt_meas = tt_meas.combine_first(tt_meas.mean(dim='new'))



# theoretical travel time estimate
tt_est_n = Li/ads.c * (1 - ads.u * np.cos(theta_i)/ ads.c - ads.v * np.sin(theta_i)/ ads.c)
tt_est_n = tt_est_n.transpose('new', 'pathID', 'time')
tt_est_n = tt_est_n.resample(time='0.5S').mean()

# uncorrected expected travel time contained in the codebase
tt_est_o = xr.DataArray(data = rttds.expectedTravelTimes.values, coords = tt_est_n.coords)
tt_meas = xr.DataArray(data = rttds.filteredMeasuredTravelTimes.transpose('new', 'pathID', 'time').values, coords = tt_est_n.coords)
tt_err_o = xr.DataArray(data = rttds.timeDeltas.transpose('new', 'pathID', 'time').values, coords = tt_est_n.coords)
tt_err_n = tt_meas - tt_est_n.values
tt_est_error =  tt_est_o-tt_est_n.values


meanWS = ads.WS.mean(dim='time')
normWS = (meanWS - meanWS.min())/(meanWS.max() - meanWS.min())
c = plt.cm.viridis(normWS)

for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), tt_err_n.mean(dim='time').isel(new=ii), color=c[ii,:])


meanWS = ads.WS.mean(dim='time')
normWS = (meanWS - meanWS.min())/(meanWS.max() - meanWS.min())
c = plt.cm.viridis(normWS)

for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), tt_err_n.mean(dim='time').isel(new=ii)/Li.values, color=c[ii,:])





from scipy.optimize import curve_fit

def cos2x(x, amp, freq, phase, offset):
    return amp * np.cos(2 * freq * x + phase) + offset

xdata = delta_theta.values.flatten()
ydata = (tt_est_error.mean(dim='time').T/Li.values[:, None]/meanWS**2).values.flatten()
    
init = [1.35*10**-8, 1, 0, 10**-8]
params, _ = curve_fit(cos2x,  xdata, ydata, init)

x = np.linspace(-np.pi, np.pi, 100)
y = cos2x(x, *params)


params


for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), tt_est_error.mean(dim='time').isel(new=ii)/Li.values/meanWS.isel(new=ii)**2, color=c[ii,:])
plt.plot(x,y, c='C2', lw=2)


tt_est_error.mean(dim=['time','new']).unstack().plot()


(tt_est_error.mean(dim=['time','new'])/Li.values).unstack().plot()


eps = tt_est_n.unstack() - tt_meas.unstack()
eps = eps.stack(pathID=['spk','mic']).dropna(dim='pathID', how='all')


for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), eps.mean(dim='time').isel(new=ii), c=Li)


for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), eps.mean(dim='time').isel(new=ii)/Li.values, c=Li)


fig, ax = plt.subplots(1,3, figsize=(15,4))
eps.unstack().mean(dim=['new','time']).plot(ax=ax[0])
(-tt_err_o).mean(dim=['new','time']).unstack().plot(ax=ax[1])
(eps+tt_err_o).mean(dim=['time','new']).unstack().plot(ax=ax[2])
fig.tight_layout()


fig, ax = plt.subplots()
ax.set_prop_cycle(color=c)
ax.plot(eps.mean(dim='time').T,)
plt.xlabel('PathID')
plt.ylabel('tt error, new method')


from scipy.optimize import curve_fit

def sinx(x, amp, freq, phase, offset):
    return amp * np.sin(freq * x + phase) + offset

xdata = delta_theta.values.flatten()
ydata = (eps.fillna(0).mean(dim='time').T/Li.values[:, None]).values.flatten()
    
init = [-1e-6, 1, 0, 1e-6]
params, _ = curve_fit(sinx,  xdata, ydata, init)

x = np.linspace(-np.pi, np.pi, 100)
y = sinx(x, *params)


plt.scatter(xdata, ydata)
plt.plot(x, y, c='C2', lw=2)


for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), eps.mean(dim='time').isel(new=ii), c=Li)
plt.plot(x, y, c='C2', lw=2)


for ii in range(19):
    plt.scatter(delta_theta.isel(new=ii), eps.mean(dim='time').isel(new=ii)/Li.values, c=Li)
plt.plot(x, y, c='C2', lw=2)


dtheta = atarray.ds.pathOrientation - ads.uDir.resample(time='0.5S').mean()


params


params[2]-2*np.pi


3.69116813e-05/2.85


ytest = -2.85 * Li * np.sin(0.975*dtheta + params[2])/ads.c**2  + Li*params[3]

plt.scatter(dtheta, ytest/Li)
plt.plot(x, y, c='C2', lw=2)



plt.plot(x, y, c='C2', lw=2)
plt.plot(x, ytest, c='C0', lw=2)


C = eps.unstack()/(Li.unstack() * np.sin(dtheta.unstack()))


C = C.stack(pathID=['spk','mic']).dropna(dim='pathID', how='all')


plt.plot(C.mean(dim=['new','time']) )


eps.unstack().mean(dim=['new','time']).plot()


eps.unstack().median(dim=['new','time']).plot()


# pid=np.random.randint(56)
tt_est_n.isel(new=1, pathID=pid).plot()
tt_meas.isel(new=1, pathID=pid).plot()
(tt_meas.isel(new=1, pathID=pid)+eps.median(dim=['new','time']).isel(pathID=pid)).plot()


pid=np.random.randint(56)
tt_est_n.isel(new=1, pathID=pid).plot()
tt_meas.isel(new=1, pathID=pid).plot()
(tt_meas.isel(new=1, pathID=pid)+eps.median(dim=['new','time']).isel(pathID=pid)).plot()


tmp = xr.DataArray(data=tt_meas.transpose('new','pathID','time').values, coords=tt_est_n.coords)


tt_meas_c = tmp+eps.median(dim=['new','time'])


eps.median(dim=['new','time']).unstack().fillna(0).values
